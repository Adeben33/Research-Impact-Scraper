{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae904b79-2c82-4a9d-b339-5632e2e204f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Finished for Nicola Luigi Bragazzi ‚Äî csv/nicola_luigi_bragazzi_impact_metrics.csv\n",
      "üéâ All authors processed. Check your output and log files.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import urllib.parse\n",
    "import logging\n",
    "import os\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "UNPAYWALL_EMAIL = \"adeniyiebenezer33@gmail.com\"\n",
    "\n",
    "# ---------- LOGGING ----------\n",
    "logging.basicConfig(\n",
    "    filename='research_impact_log.txt',\n",
    "    filemode='a',\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    level=logging.INFO\n",
    ")\n",
    "\n",
    "# ---------- KEYWORDS ----------\n",
    "public_health_keywords = [\n",
    "    \"public health\", \"infectious disease\", \"epidemiology\", \"mathematical modeling\",\n",
    "    \"COVID-19\", \"cholera\", \"malaria\", \"pandemic\", \"outbreak\", \"disease mitigation\",\n",
    "    \"early warning systems\", \"community response\", \"health systems\", \"health equity\",\n",
    "    \"vaccination\", \"surveillance\", \"data-driven decision-making\", \"risk communication\",\n",
    "    \"contact tracing\", \"behavior change\", \"public engagement\", \"intervention\", \"awareness\"\n",
    "]\n",
    "\n",
    "capacity_building_keywords = [\n",
    "    \"training\", \"capacity\", \"leadership\", \"sustainability\", \"skills development\", \"education\",\n",
    "    \"data science training\", \"epidemiological training\", \"south-south collaboration\",\n",
    "    \"research network\", \"mentorship\", \"interdisciplinary teams\", \"technology transfer\",\n",
    "    \"local expertise\", \"workforce development\", \"collaborative learning\",\n",
    "    \"public health training\", \"AI and data innovation\", \"institutional strengthening\", \"infrastructure building\"\n",
    "]\n",
    "\n",
    "# ---------- HELPER FUNCTIONS ----------\n",
    "def search_openalex_author_id(name):\n",
    "    query = urllib.parse.quote(name)\n",
    "    url = f\"https://api.openalex.org/authors?search={query}\"\n",
    "    r = requests.get(url)\n",
    "    if r.status_code == 200:\n",
    "        data = r.json()\n",
    "        if data.get(\"results\"):\n",
    "            return data[\"results\"][0][\"id\"], data[\"results\"][0][\"display_name\"]\n",
    "    return None, None\n",
    "\n",
    "def get_openalex_author_works(author_id, max_results=1000):\n",
    "    base_url = f\"https://api.openalex.org/works?filter=author.id:{author_id}&per-page=200\"\n",
    "    works = []\n",
    "    cursor = \"*\"\n",
    "    count = 0\n",
    "    while cursor and count < max_results:\n",
    "        url = f\"{base_url}&cursor={cursor}\"\n",
    "        r = requests.get(url)\n",
    "        if r.status_code != 200:\n",
    "            logging.warning(f\"Failed to fetch works (status: {r.status_code})\")\n",
    "            break\n",
    "        data = r.json()\n",
    "        works.extend(data.get(\"results\", []))\n",
    "        cursor = data.get(\"meta\", {}).get(\"next_cursor\", None)\n",
    "        count += len(data.get(\"results\", []))\n",
    "        time.sleep(1)\n",
    "    return works\n",
    "\n",
    "def get_altmetric_summary(doi):\n",
    "    url = f\"https://api.altmetric.com/v1/doi/{doi}\"\n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "        if r.status_code == 200:\n",
    "            data = r.json()\n",
    "            return {\n",
    "                \"altmetric_id\": data.get(\"id\"),\n",
    "                \"score\": data.get(\"score\", 0),\n",
    "                \"counts\": {\n",
    "                    'Twitter': data.get('cited_by_tweeters_count', 0),\n",
    "                    'Reddit': data.get('cited_by_rdts_count', 0),\n",
    "                    'Blogs': data.get('cited_by_feeds_count', 0),\n",
    "                    'News': data.get('cited_by_msm_count', 0),\n",
    "                    'Facebook': data.get('cited_by_fbwalls_count', 0),\n",
    "                    'Wikipedia': data.get('cited_by_wikipedia_count', 0),\n",
    "                    'Policy Docs': data.get('cited_by_policy_count', 0)\n",
    "                }\n",
    "            }\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Altmetric error for DOI {doi}: {e}\")\n",
    "    return None\n",
    "\n",
    "def get_altmetric_sources(altmetric_id):\n",
    "    url = f\"https://api.altmetric.com/v1/id/{altmetric_id}\"\n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "        if r.status_code == 200:\n",
    "            data = r.json()\n",
    "            posts = data.get(\"posts\", [])\n",
    "            return [post.get(\"url\") for post in posts if \"url\" in post][:10]\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Source retrieval error for altmetric ID {altmetric_id}: {e}\")\n",
    "    return []\n",
    "\n",
    "def get_open_access_status(doi):\n",
    "    url = f\"https://api.unpaywall.org/v2/{doi}?email={UNPAYWALL_EMAIL}\"\n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "        if r.status_code == 200:\n",
    "            data = r.json()\n",
    "            return data.get(\"is_oa\", False), data.get(\"oa_status\", \"unknown\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Unpaywall error for DOI {doi}: {e}\")\n",
    "    return None, None\n",
    "\n",
    "def tag_keywords(text, keyword_list):\n",
    "    text = text.lower()\n",
    "    return any(k in text for k in keyword_list)\n",
    "\n",
    "# ---------- MAIN PROCESSING ----------\n",
    "def process_author(search_name):\n",
    "    logging.info(f\"üîç Starting collection for: {search_name}\")\n",
    "    author_id, author_name = search_openalex_author_id(search_name)\n",
    "    if not author_id:\n",
    "        logging.warning(f\"No OpenAlex author found for: {search_name}\")\n",
    "        print(f\"‚ùå No author found for: {search_name}\")\n",
    "        return\n",
    "\n",
    "    works = get_openalex_author_works(author_id)\n",
    "    unique_works = {w['doi']: w for w in works if w.get(\"doi\")}.values()\n",
    "    logging.info(f\"Found {len(unique_works)} unique works with DOIs for {author_name}\")\n",
    "\n",
    "    results = []\n",
    "    for work in unique_works:\n",
    "        doi = work.get(\"doi\")\n",
    "        title = work.get(\"title\", \"Untitled\")\n",
    "        year = work.get(\"publication_year\", \"N/A\")\n",
    "        citations = work.get(\"cited_by_count\", 0)\n",
    "        authors = \"; \".join([auth['author']['display_name'] for auth in work.get(\"authorships\", [])])\n",
    "        venue = work.get(\"host_venue\", {}).get(\"display_name\", \"N/A\")\n",
    "        fields = \"; \".join([c[\"display_name\"] for c in work.get(\"concepts\", [])])\n",
    "        pub_type = \"Preprint\" if work.get(\"type\") == \"posted-content\" else \"Published\"\n",
    "\n",
    "        altmetric = get_altmetric_summary(doi)\n",
    "        altmetric_id = altmetric.get(\"altmetric_id\") if altmetric else None\n",
    "        sources = get_altmetric_sources(altmetric_id) if altmetric_id else []\n",
    "\n",
    "        oa_flag, oa_status = get_open_access_status(doi)\n",
    "\n",
    "        results.append({\n",
    "            \"Author\": author_name,\n",
    "            \"Paper Title\": title,\n",
    "            \"Year\": year,\n",
    "            \"Publication Type\": pub_type,\n",
    "            \"Citations\": citations,\n",
    "            \"DOI\": doi,\n",
    "            \"Authors\": authors,\n",
    "            \"Journal\": venue,\n",
    "            \"Fields\": fields,\n",
    "            \"Altmetric Score\": altmetric.get(\"score\", 0) if altmetric else 0,\n",
    "            \"Twitter Mentions\": altmetric.get(\"counts\", {}).get(\"Twitter\", 0) if altmetric else 0,\n",
    "            \"Reddit Mentions\": altmetric.get(\"counts\", {}).get(\"Reddit\", 0) if altmetric else 0,\n",
    "            \"News Mentions\": altmetric.get(\"counts\", {}).get(\"News\", 0) if altmetric else 0,\n",
    "            \"Policy Mentions\": altmetric.get(\"counts\", {}).get(\"Policy Docs\", 0) if altmetric else 0,\n",
    "            \"Mention URLs\": \"; \".join(sources),\n",
    "            \"Open Access\": oa_flag,\n",
    "            \"OA Status\": oa_status,\n",
    "            \"Public Health Impact\": tag_keywords(title, public_health_keywords),\n",
    "            \"Capacity Building\": tag_keywords(title, capacity_building_keywords)\n",
    "        })\n",
    "        time.sleep(1)\n",
    "\n",
    "    if results:\n",
    "        df = pd.DataFrame(results)\n",
    "        safe_name = search_name.lower().replace(' ', '_')\n",
    "\n",
    "        os.makedirs(\"csv\", exist_ok=True)\n",
    "        os.makedirs(\"json\", exist_ok=True)\n",
    "\n",
    "        csv_file = f\"csv/{safe_name}_impact_metrics.csv\"\n",
    "        json_file = f\"json/{safe_name}_impact_metrics.json\"\n",
    "\n",
    "        df.to_csv(csv_file, index=False)\n",
    "        df.to_json(json_file, orient=\"records\", indent=2)\n",
    "\n",
    "        logging.info(f\"‚úÖ Saved for {search_name}: {csv_file}, {json_file}\")\n",
    "        print(f\"‚úÖ Finished for {search_name} ‚Äî {csv_file}\")\n",
    "    else:\n",
    "        logging.warning(f\"No valid papers found for {search_name}\")\n",
    "        print(f\"‚ö†Ô∏è No valid papers found for {search_name}\")\n",
    "\n",
    "# ---------- AUTHOR LOOP ----------\n",
    "author_list = [\n",
    "    \"Nicola Luigi Bragazzi\"\n",
    "]\n",
    "\n",
    "for name in author_list:\n",
    "    process_author(name)\n",
    "\n",
    "print(\"üéâ All authors processed. Check your output and log files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9308989-ee21-41fe-bca2-d84ec6184a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Finished for Nicola Luigi Bragazzi ‚Äî csv/nicola_luigi_bragazzi_impact_metrics.csv\n",
      "üéâ All authors processed. Check your output and log files.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "from scholarly import scholarly\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "UNPAYWALL_EMAIL = \"adeniyiebenezer33@gmail.com\"\n",
    "DEBUG_MODE = True\n",
    "\n",
    "# ---------- LOGGING ----------\n",
    "logging.basicConfig(\n",
    "    filename='research_impact_log.txt',\n",
    "    filemode='a',\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    level=logging.INFO\n",
    ")\n",
    "\n",
    "# ---------- DOI + PMID HELPERS ----------\n",
    "def clean_doi(doi):\n",
    "    if not doi:\n",
    "        return None\n",
    "    if doi.startswith(\"https://doi.org/\"):\n",
    "        return doi.replace(\"https://doi.org/\", \"\")\n",
    "    if \"doi.org\" not in doi:\n",
    "        return None\n",
    "    return doi\n",
    "\n",
    "def query_doi_from_openalex(title, author=None):\n",
    "    title_clean = re.sub(r'[^\\w\\s]', '', title.lower())[:200]\n",
    "    query = f\"title.search:{title_clean}\"\n",
    "    if author:\n",
    "        query += f\" AND author.display_name.search:{author}\"\n",
    "    url = f\"https://api.openalex.org/works?filter={query}&per-page=1\"\n",
    "    try:\n",
    "        r = requests.get(url, timeout=10)\n",
    "        if r.status_code == 200:\n",
    "            results = r.json().get(\"results\", [])\n",
    "            if results:\n",
    "                work = results[0]\n",
    "                return work.get(\"doi\", \"\").replace(\"https://doi.org/\", \"\"), work.get(\"ids\", {}).get(\"pmid\")\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"OpenAlex DOI lookup failed for '{title}': {e}\")\n",
    "    return None, None\n",
    "\n",
    "def query_doi_from_crossref(title):\n",
    "    url = f\"https://api.crossref.org/works?query.title={requests.utils.quote(title)}&rows=1\"\n",
    "    try:\n",
    "        r = requests.get(url, timeout=10)\n",
    "        if r.status_code == 200:\n",
    "            items = r.json()[\"message\"].get(\"items\", [])\n",
    "            if items:\n",
    "                return items[0].get(\"DOI\"), None\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Crossref DOI lookup failed for '{title}': {e}\")\n",
    "    return None, None\n",
    "\n",
    "def get_pmid_from_pubmed(title):\n",
    "    url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi\"\n",
    "    params = {\n",
    "        \"db\": \"pubmed\",\n",
    "        \"retmode\": \"json\",\n",
    "        \"term\": title\n",
    "    }\n",
    "    try:\n",
    "        r = requests.get(url, params=params, timeout=10)\n",
    "        ids = r.json().get(\"esearchresult\", {}).get(\"idlist\", [])\n",
    "        return ids[0] if ids else None\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"PubMed PMID lookup failed for '{title}': {e}\")\n",
    "    return None\n",
    "\n",
    "# ---------- ALTMETRIC & OA ----------\n",
    "def get_altmetric_summary(doi, pmid=None, title=None, altmetric_404_log=None):\n",
    "    url = f\"https://api.altmetric.com/v1/doi/{doi}\"\n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "        if DEBUG_MODE:\n",
    "            print(f\"üîó Altmetric URL: {url} ‚Äî Status: {r.status_code}\")\n",
    "        if r.status_code == 200:\n",
    "            return extract_altmetric_data(r.json())\n",
    "        elif r.status_code == 404:\n",
    "            if title and altmetric_404_log is not None:\n",
    "                altmetric_404_log.append(title)\n",
    "            return get_altmetric_by_pmid(pmid) if pmid else None\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Altmetric error for DOI {doi}: {e}\")\n",
    "    return None\n",
    "\n",
    "def get_altmetric_by_pmid(pmid):\n",
    "    url = f\"https://api.altmetric.com/v1/pmid/{pmid}\"\n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "        if DEBUG_MODE:\n",
    "            print(f\"üîó Altmetric PMID URL: {url} ‚Äî Status: {r.status_code}\")\n",
    "        if r.status_code == 200:\n",
    "            return extract_altmetric_data(r.json())\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Altmetric error for PMID {pmid}: {e}\")\n",
    "    return None\n",
    "\n",
    "def extract_altmetric_data(data):\n",
    "    return {\n",
    "        \"altmetric_id\": data.get(\"id\"),\n",
    "        \"score\": data.get(\"score\", 0),\n",
    "        \"counts\": {\n",
    "            'Twitter': data.get('cited_by_tweeters_count', 0),\n",
    "            'Reddit': data.get('cited_by_rdts_count', 0),\n",
    "            'Blogs': data.get('cited_by_feeds_count', 0),\n",
    "            'News': data.get('cited_by_msm_count', 0),\n",
    "            'Facebook': data.get('cited_by_fbwalls_count', 0),\n",
    "            'Wikipedia': data.get('cited_by_wikipedia_count', 0),\n",
    "            'Policy Docs': data.get('cited_by_policy_count', 0)\n",
    "        }\n",
    "    }\n",
    "\n",
    "def get_open_access_status(doi):\n",
    "    url = f\"https://api.unpaywall.org/v2/{doi}?email={UNPAYWALL_EMAIL}\"\n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "        if r.status_code == 200:\n",
    "            data = r.json()\n",
    "            return data.get(\"is_oa\", False), data.get(\"oa_status\", \"unknown\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Unpaywall error for DOI {doi}: {e}\")\n",
    "    return None, None\n",
    "\n",
    "# ---------- HELPERS ----------\n",
    "def tag_keywords(text, keyword_list):\n",
    "    return any(k in text.lower() for k in keyword_list)\n",
    "\n",
    "def has_media_mentions(altmetric):\n",
    "    if not altmetric:\n",
    "        return False\n",
    "    counts = altmetric.get(\"counts\", {})\n",
    "    return any(counts.get(k, 0) > 0 for k in ['News', 'Blogs', 'Policy Docs', 'Facebook', 'Wikipedia'])\n",
    "\n",
    "def is_preprint(venue, doi):\n",
    "    if doi:\n",
    "        return False\n",
    "    preprint_sources = [\"arxiv\", \"biorxiv\", \"medrxiv\", \"ssrn\", \"osf\", \"researchsquare\", \"preprints\"]\n",
    "    return any(src in venue.lower() for src in preprint_sources) if venue else False\n",
    "\n",
    "# ---------- GOOGLE SCHOLAR ----------\n",
    "def get_author_by_user_id(user_id):\n",
    "    try:\n",
    "        author = scholarly.search_author_id(user_id)\n",
    "        filled = scholarly.fill(author)\n",
    "        return filled, filled['name']\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error fetching scholar profile for user ID {user_id}: {e}\")\n",
    "    return None, None\n",
    "\n",
    "def get_scholar_publications(filled_author, max_results=300):\n",
    "    publications = []\n",
    "    for pub in filled_author.get('publications', [])[:max_results]:\n",
    "        try:\n",
    "            detailed = scholarly.fill(pub)\n",
    "            title = detailed['bib'].get(\"title\", \"Untitled\")\n",
    "            year = detailed['bib'].get(\"pub_year\", \"N/A\")\n",
    "            authors = detailed['bib'].get(\"author\", \"\")\n",
    "            venue = detailed['bib'].get(\"journal\") or detailed['bib'].get(\"venue\") or detailed['bib'].get(\"pub\") or \"N/A\"\n",
    "            citations = detailed.get(\"num_citations\", 0)\n",
    "            doi = detailed.get(\"pub_url\", \"\")\n",
    "            publications.append({\n",
    "                \"title\": title,\n",
    "                \"year\": year,\n",
    "                \"authors\": authors,\n",
    "                \"venue\": venue,\n",
    "                \"citations\": citations,\n",
    "                \"doi\": doi\n",
    "            })\n",
    "            time.sleep(1)\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Failed to fill publication: {e}\")\n",
    "    return publications\n",
    "\n",
    "# ---------- PROCESS ----------\n",
    "def process_author(author_name, profile, works):\n",
    "    safe_name = author_name.lower().replace(' ', '_')\n",
    "    os.makedirs(safe_name, exist_ok=True)\n",
    "    results = []\n",
    "    altmetric_404_titles = []\n",
    "\n",
    "    # Save author-level metrics\n",
    "    profile_metrics = {\n",
    "        \"Author\": author_name,\n",
    "        \"Citations_All\": profile.get(\"citedby\", 0),\n",
    "        \"Citations_Since2020\": profile.get(\"citedby5y\", 0),\n",
    "        \"h_index_All\": profile.get(\"hindex\", 0),\n",
    "        \"h_index_Since2020\": profile.get(\"hindex5y\", 0),\n",
    "        \"i10_index_All\": profile.get(\"i10index\", 0),\n",
    "        \"i10_index_Since2020\": profile.get(\"i10index5y\", 0)\n",
    "    }\n",
    "    pd.DataFrame([profile_metrics]).to_csv(f\"{safe_name}/metrics.csv\", index=False)\n",
    "\n",
    "    for work in works:\n",
    "        title = work.get(\"title\", \"Untitled\")\n",
    "        year = work.get(\"year\", \"N/A\")\n",
    "        authors = work.get(\"authors\", \"\")\n",
    "        venue = work.get(\"venue\", \"N/A\")\n",
    "        citations = work.get(\"citations\", 0)\n",
    "        raw_doi = work.get(\"doi\", \"\")\n",
    "        doi = clean_doi(raw_doi)\n",
    "\n",
    "        pmid = None\n",
    "        if not doi:\n",
    "            doi, pmid = query_doi_from_openalex(title, author_name)\n",
    "            if not doi:\n",
    "                doi, _ = query_doi_from_crossref(title)\n",
    "        if not pmid:\n",
    "            pmid = get_pmid_from_pubmed(title)\n",
    "\n",
    "        if not doi and not pmid:\n",
    "            logging.info(f\"‚ùå Skipping ‚Äî No DOI or PMID found for: {title}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"üìÑ Processing: {title} ({doi if doi else 'No DOI'})\")\n",
    "        altmetric = get_altmetric_summary(doi, pmid, title=title, altmetric_404_log=altmetric_404_titles)\n",
    "        media_flag = has_media_mentions(altmetric)\n",
    "        counts = altmetric.get(\"counts\", {}) if altmetric else {}\n",
    "        oa_flag, oa_status = get_open_access_status(doi) if doi else (None, None)\n",
    "\n",
    "        results.append({\n",
    "            \"Author\": author_name,\n",
    "            \"Paper Title\": title,\n",
    "            \"Year\": year,\n",
    "            \"Citations\": citations,\n",
    "            \"DOI\": f\"https://doi.org/{doi}\" if doi else \"N/A\",\n",
    "            \"PMID\": pmid,\n",
    "            \"Authors\": authors,\n",
    "            \"Journal\": venue,\n",
    "            \"Altmetric Score\": altmetric.get(\"score\") if altmetric else 0,\n",
    "            \"Twitter Mentions\": counts.get(\"Twitter\", 0),\n",
    "            \"Reddit Mentions\": counts.get(\"Reddit\", 0),\n",
    "            \"News Mentions\": counts.get(\"News\", 0),\n",
    "            \"Blog Mentions\": counts.get(\"Blogs\", 0),\n",
    "            \"Facebook Mentions\": counts.get(\"Facebook\", 0),\n",
    "            \"Wikipedia Mentions\": counts.get(\"Wikipedia\", 0),\n",
    "            \"Policy Mentions\": counts.get(\"Policy Docs\", 0),\n",
    "            \"Media Mentioned\": media_flag,\n",
    "            \"Open Access\": oa_flag,\n",
    "            \"OA Status\": oa_status,\n",
    "            \"Preprint\": is_preprint(venue, doi),\n",
    "            \"Public Health Impact\": tag_keywords(title, public_health_keywords),\n",
    "            \"Capacity Building\": tag_keywords(title, capacity_building_keywords)\n",
    "        })\n",
    "        time.sleep(2)\n",
    "\n",
    "    if results:\n",
    "        df = pd.DataFrame(results)\n",
    "        df.to_csv(f\"{safe_name}/impact_metrics.csv\", index=False)\n",
    "        df.to_json(f\"{safe_name}/impact_metrics.json\", orient=\"records\", indent=2)\n",
    "        print(f\"‚úÖ Finished for {author_name} ‚Äî {len(results)} papers saved.\")\n",
    "\n",
    "    if altmetric_404_titles:\n",
    "        pd.DataFrame(altmetric_404_titles, columns=[\"Title\"]).to_csv(\n",
    "            f\"{safe_name}/altmetric_404.csv\", index=False\n",
    "        )\n",
    "        print(f\"‚ö†Ô∏è {len(altmetric_404_titles)} papers returned Altmetric 404. Saved to CSV.\")\n",
    "\n",
    "# ---------- KEYWORDS ----------\n",
    "public_health_keywords = [\n",
    "    \"public health\", \"infectious disease\", \"epidemiology\", \"mathematical modeling\",\n",
    "    \"COVID-19\", \"cholera\", \"malaria\", \"pandemic\", \"outbreak\", \"disease mitigation\",\n",
    "    \"early warning systems\", \"community response\", \"health systems\", \"health equity\",\n",
    "    \"vaccination\", \"surveillance\", \"data-driven decision-making\", \"risk communication\",\n",
    "    \"contact tracing\", \"behavior change\", \"public engagement\", \"intervention\", \"awareness\"\n",
    "]\n",
    "\n",
    "capacity_building_keywords = [\n",
    "    \"training\", \"capacity\", \"leadership\", \"sustainability\", \"skills development\", \"education\",\n",
    "    \"data science training\", \"epidemiological training\", \"south-south collaboration\",\n",
    "    \"research network\", \"mentorship\", \"interdisciplinary teams\", \"technology transfer\",\n",
    "    \"local expertise\", \"workforce development\", \"collaborative learning\",\n",
    "    \"public health training\", \"AI and data innovation\", \"institutional strengthening\", \"infrastructure building\"\n",
    "]\n",
    "\n",
    "# ---------- AUTHOR DICTIONARY ----------\n",
    "author_dict = {\n",
    "    \"Nicola Luigi Bragazzi\": \"sTIzwwEAAAAJ\",\n",
    "}\n",
    "\n",
    "# ---------- EXECUTION ----------\n",
    "for author_name, user_id in author_dict.items():\n",
    "    print(f\"üîç Retrieving data for {author_name}...\")\n",
    "    profile, _ = get_author_by_user_id(user_id)\n",
    "    if profile:\n",
    "        works = get_scholar_publications(profile)\n",
    "        process_author(author_name, profile, works)\n",
    "    else:\n",
    "        print(f\"‚ùå Could not retrieve profile for {author_name}\")\n",
    "\n",
    "print(\"üéâ All authors processed. Check your output folders.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b6e2f2-aa3d-4824-8037-17f338959522",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
