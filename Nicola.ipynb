{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae904b79-2c82-4a9d-b339-5632e2e204f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Finished for Nicola Luigi Bragazzi — csv/nicola_luigi_bragazzi_impact_metrics.csv\n",
      "🎉 All authors processed. Check your output and log files.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import urllib.parse\n",
    "import logging\n",
    "import os\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "UNPAYWALL_EMAIL = \"adeniyiebenezer33@gmail.com\"\n",
    "\n",
    "# ---------- LOGGING ----------\n",
    "logging.basicConfig(\n",
    "    filename='research_impact_log.txt',\n",
    "    filemode='a',\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    level=logging.INFO\n",
    ")\n",
    "\n",
    "# ---------- KEYWORDS ----------\n",
    "public_health_keywords = [\n",
    "    \"public health\", \"infectious disease\", \"epidemiology\", \"mathematical modeling\",\n",
    "    \"COVID-19\", \"cholera\", \"malaria\", \"pandemic\", \"outbreak\", \"disease mitigation\",\n",
    "    \"early warning systems\", \"community response\", \"health systems\", \"health equity\",\n",
    "    \"vaccination\", \"surveillance\", \"data-driven decision-making\", \"risk communication\",\n",
    "    \"contact tracing\", \"behavior change\", \"public engagement\", \"intervention\", \"awareness\"\n",
    "]\n",
    "\n",
    "capacity_building_keywords = [\n",
    "    \"training\", \"capacity\", \"leadership\", \"sustainability\", \"skills development\", \"education\",\n",
    "    \"data science training\", \"epidemiological training\", \"south-south collaboration\",\n",
    "    \"research network\", \"mentorship\", \"interdisciplinary teams\", \"technology transfer\",\n",
    "    \"local expertise\", \"workforce development\", \"collaborative learning\",\n",
    "    \"public health training\", \"AI and data innovation\", \"institutional strengthening\", \"infrastructure building\"\n",
    "]\n",
    "\n",
    "# ---------- HELPER FUNCTIONS ----------\n",
    "def search_openalex_author_id(name):\n",
    "    query = urllib.parse.quote(name)\n",
    "    url = f\"https://api.openalex.org/authors?search={query}\"\n",
    "    r = requests.get(url)\n",
    "    if r.status_code == 200:\n",
    "        data = r.json()\n",
    "        if data.get(\"results\"):\n",
    "            return data[\"results\"][0][\"id\"], data[\"results\"][0][\"display_name\"]\n",
    "    return None, None\n",
    "\n",
    "def get_openalex_author_works(author_id, max_results=1000):\n",
    "    base_url = f\"https://api.openalex.org/works?filter=author.id:{author_id}&per-page=200\"\n",
    "    works = []\n",
    "    cursor = \"*\"\n",
    "    count = 0\n",
    "    while cursor and count < max_results:\n",
    "        url = f\"{base_url}&cursor={cursor}\"\n",
    "        r = requests.get(url)\n",
    "        if r.status_code != 200:\n",
    "            logging.warning(f\"Failed to fetch works (status: {r.status_code})\")\n",
    "            break\n",
    "        data = r.json()\n",
    "        works.extend(data.get(\"results\", []))\n",
    "        cursor = data.get(\"meta\", {}).get(\"next_cursor\", None)\n",
    "        count += len(data.get(\"results\", []))\n",
    "        time.sleep(1)\n",
    "    return works\n",
    "\n",
    "def get_altmetric_summary(doi):\n",
    "    url = f\"https://api.altmetric.com/v1/doi/{doi}\"\n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "        if r.status_code == 200:\n",
    "            data = r.json()\n",
    "            return {\n",
    "                \"altmetric_id\": data.get(\"id\"),\n",
    "                \"score\": data.get(\"score\", 0),\n",
    "                \"counts\": {\n",
    "                    'Twitter': data.get('cited_by_tweeters_count', 0),\n",
    "                    'Reddit': data.get('cited_by_rdts_count', 0),\n",
    "                    'Blogs': data.get('cited_by_feeds_count', 0),\n",
    "                    'News': data.get('cited_by_msm_count', 0),\n",
    "                    'Facebook': data.get('cited_by_fbwalls_count', 0),\n",
    "                    'Wikipedia': data.get('cited_by_wikipedia_count', 0),\n",
    "                    'Policy Docs': data.get('cited_by_policy_count', 0)\n",
    "                }\n",
    "            }\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Altmetric error for DOI {doi}: {e}\")\n",
    "    return None\n",
    "\n",
    "def get_altmetric_sources(altmetric_id):\n",
    "    url = f\"https://api.altmetric.com/v1/id/{altmetric_id}\"\n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "        if r.status_code == 200:\n",
    "            data = r.json()\n",
    "            posts = data.get(\"posts\", [])\n",
    "            return [post.get(\"url\") for post in posts if \"url\" in post][:10]\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Source retrieval error for altmetric ID {altmetric_id}: {e}\")\n",
    "    return []\n",
    "\n",
    "def get_open_access_status(doi):\n",
    "    url = f\"https://api.unpaywall.org/v2/{doi}?email={UNPAYWALL_EMAIL}\"\n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "        if r.status_code == 200:\n",
    "            data = r.json()\n",
    "            return data.get(\"is_oa\", False), data.get(\"oa_status\", \"unknown\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Unpaywall error for DOI {doi}: {e}\")\n",
    "    return None, None\n",
    "\n",
    "def tag_keywords(text, keyword_list):\n",
    "    text = text.lower()\n",
    "    return any(k in text for k in keyword_list)\n",
    "\n",
    "# ---------- MAIN PROCESSING ----------\n",
    "def process_author(search_name):\n",
    "    logging.info(f\"🔍 Starting collection for: {search_name}\")\n",
    "    author_id, author_name = search_openalex_author_id(search_name)\n",
    "    if not author_id:\n",
    "        logging.warning(f\"No OpenAlex author found for: {search_name}\")\n",
    "        print(f\"❌ No author found for: {search_name}\")\n",
    "        return\n",
    "\n",
    "    works = get_openalex_author_works(author_id)\n",
    "    unique_works = {w['doi']: w for w in works if w.get(\"doi\")}.values()\n",
    "    logging.info(f\"Found {len(unique_works)} unique works with DOIs for {author_name}\")\n",
    "\n",
    "    results = []\n",
    "    for work in unique_works:\n",
    "        doi = work.get(\"doi\")\n",
    "        title = work.get(\"title\", \"Untitled\")\n",
    "        year = work.get(\"publication_year\", \"N/A\")\n",
    "        citations = work.get(\"cited_by_count\", 0)\n",
    "        authors = \"; \".join([auth['author']['display_name'] for auth in work.get(\"authorships\", [])])\n",
    "        venue = work.get(\"host_venue\", {}).get(\"display_name\", \"N/A\")\n",
    "        fields = \"; \".join([c[\"display_name\"] for c in work.get(\"concepts\", [])])\n",
    "        pub_type = \"Preprint\" if work.get(\"type\") == \"posted-content\" else \"Published\"\n",
    "\n",
    "        altmetric = get_altmetric_summary(doi)\n",
    "        altmetric_id = altmetric.get(\"altmetric_id\") if altmetric else None\n",
    "        sources = get_altmetric_sources(altmetric_id) if altmetric_id else []\n",
    "\n",
    "        oa_flag, oa_status = get_open_access_status(doi)\n",
    "\n",
    "        results.append({\n",
    "            \"Author\": author_name,\n",
    "            \"Paper Title\": title,\n",
    "            \"Year\": year,\n",
    "            \"Publication Type\": pub_type,\n",
    "            \"Citations\": citations,\n",
    "            \"DOI\": doi,\n",
    "            \"Authors\": authors,\n",
    "            \"Journal\": venue,\n",
    "            \"Fields\": fields,\n",
    "            \"Altmetric Score\": altmetric.get(\"score\", 0) if altmetric else 0,\n",
    "            \"Twitter Mentions\": altmetric.get(\"counts\", {}).get(\"Twitter\", 0) if altmetric else 0,\n",
    "            \"Reddit Mentions\": altmetric.get(\"counts\", {}).get(\"Reddit\", 0) if altmetric else 0,\n",
    "            \"News Mentions\": altmetric.get(\"counts\", {}).get(\"News\", 0) if altmetric else 0,\n",
    "            \"Policy Mentions\": altmetric.get(\"counts\", {}).get(\"Policy Docs\", 0) if altmetric else 0,\n",
    "            \"Mention URLs\": \"; \".join(sources),\n",
    "            \"Open Access\": oa_flag,\n",
    "            \"OA Status\": oa_status,\n",
    "            \"Public Health Impact\": tag_keywords(title, public_health_keywords),\n",
    "            \"Capacity Building\": tag_keywords(title, capacity_building_keywords)\n",
    "        })\n",
    "        time.sleep(1)\n",
    "\n",
    "    if results:\n",
    "        df = pd.DataFrame(results)\n",
    "        safe_name = search_name.lower().replace(' ', '_')\n",
    "\n",
    "        os.makedirs(\"csv\", exist_ok=True)\n",
    "        os.makedirs(\"json\", exist_ok=True)\n",
    "\n",
    "        csv_file = f\"csv/{safe_name}_impact_metrics.csv\"\n",
    "        json_file = f\"json/{safe_name}_impact_metrics.json\"\n",
    "\n",
    "        df.to_csv(csv_file, index=False)\n",
    "        df.to_json(json_file, orient=\"records\", indent=2)\n",
    "\n",
    "        logging.info(f\"✅ Saved for {search_name}: {csv_file}, {json_file}\")\n",
    "        print(f\"✅ Finished for {search_name} — {csv_file}\")\n",
    "    else:\n",
    "        logging.warning(f\"No valid papers found for {search_name}\")\n",
    "        print(f\"⚠️ No valid papers found for {search_name}\")\n",
    "\n",
    "# ---------- AUTHOR LOOP ----------\n",
    "author_list = [\n",
    "    \"Nicola Luigi Bragazzi\"\n",
    "]\n",
    "\n",
    "for name in author_list:\n",
    "    process_author(name)\n",
    "\n",
    "print(\"🎉 All authors processed. Check your output and log files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9308989-ee21-41fe-bca2-d84ec6184a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ No valid papers found for Nicola Luigi Bragazzi\n",
      "🎉 All authors processed. Check your output and log files.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import urllib.parse\n",
    "import logging\n",
    "import os\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "UNPAYWALL_EMAIL = \"adeniyiebenezer33@gmail.com\"\n",
    "\n",
    "# ---------- LOGGING ----------\n",
    "logging.basicConfig(\n",
    "    filename='research_impact_log.txt',\n",
    "    filemode='a',\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    level=logging.INFO\n",
    ")\n",
    "\n",
    "# ---------- KEYWORDS ----------\n",
    "public_health_keywords = [\n",
    "    \"public health\", \"infectious disease\", \"epidemiology\", \"mathematical modeling\",\n",
    "    \"COVID-19\", \"cholera\", \"malaria\", \"pandemic\", \"outbreak\", \"disease mitigation\",\n",
    "    \"early warning systems\", \"community response\", \"health systems\", \"health equity\",\n",
    "    \"vaccination\", \"surveillance\", \"data-driven decision-making\", \"risk communication\",\n",
    "    \"contact tracing\", \"behavior change\", \"public engagement\", \"intervention\", \"awareness\"\n",
    "]\n",
    "\n",
    "capacity_building_keywords = [\n",
    "    \"training\", \"capacity\", \"leadership\", \"sustainability\", \"skills development\", \"education\",\n",
    "    \"data science training\", \"epidemiological training\", \"south-south collaboration\",\n",
    "    \"research network\", \"mentorship\", \"interdisciplinary teams\", \"technology transfer\",\n",
    "    \"local expertise\", \"workforce development\", \"collaborative learning\",\n",
    "    \"public health training\", \"AI and data innovation\", \"institutional strengthening\", \"infrastructure building\"\n",
    "]\n",
    "\n",
    "# ---------- HELPER FUNCTIONS ----------\n",
    "def search_openalex_author_id(name):\n",
    "    query = urllib.parse.quote(name)\n",
    "    url = f\"https://api.openalex.org/authors?search={query}\"\n",
    "    r = requests.get(url)\n",
    "    if r.status_code == 200:\n",
    "        data = r.json()\n",
    "        if data.get(\"results\"):\n",
    "            return data[\"results\"][0][\"id\"], data[\"results\"][0][\"display_name\"]\n",
    "    return None, None\n",
    "\n",
    "def get_openalex_author_works(author_id, max_results=5000):\n",
    "    works = []\n",
    "    cursor = \"*\"\n",
    "    count = 0\n",
    "    page_size = 500\n",
    "    base_url = f\"https://api.openalex.org/works?filter=author.id:{author_id}&per_page={page_size}&mailto={UNPAYWALL_EMAIL}\"\n",
    "\n",
    "    while cursor and count < max_results:\n",
    "        url = f\"{base_url}&cursor={urllib.parse.quote(cursor)}\"\n",
    "        r = requests.get(url)\n",
    "        if r.status_code != 200:\n",
    "            logging.warning(f\"Failed to fetch works (status: {r.status_code})\")\n",
    "            break\n",
    "        data = r.json()\n",
    "        results = data.get(\"results\", [])\n",
    "        works.extend(results)\n",
    "        cursor = data.get(\"meta\", {}).get(\"next_cursor\", None)\n",
    "        count += len(results)\n",
    "        time.sleep(1)  # Be polite to the API\n",
    "\n",
    "    return works\n",
    "\n",
    "def get_altmetric_summary(doi):\n",
    "    url = f\"https://api.altmetric.com/v1/doi/{doi}\"\n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "        if r.status_code == 200:\n",
    "            data = r.json()\n",
    "            return {\n",
    "                \"altmetric_id\": data.get(\"id\"),\n",
    "                \"score\": data.get(\"score\", 0),\n",
    "                \"counts\": {\n",
    "                    'Twitter': data.get('cited_by_tweeters_count', 0),\n",
    "                    'Reddit': data.get('cited_by_rdts_count', 0),\n",
    "                    'Blogs': data.get('cited_by_feeds_count', 0),\n",
    "                    'News': data.get('cited_by_msm_count', 0),\n",
    "                    'Facebook': data.get('cited_by_fbwalls_count', 0),\n",
    "                    'Wikipedia': data.get('cited_by_wikipedia_count', 0),\n",
    "                    'Policy Docs': data.get('cited_by_policy_count', 0)\n",
    "                }\n",
    "            }\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Altmetric error for DOI {doi}: {e}\")\n",
    "    return None\n",
    "\n",
    "def get_altmetric_sources(altmetric_id):\n",
    "    url = f\"https://api.altmetric.com/v1/id/{altmetric_id}\"\n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "        if r.status_code == 200:\n",
    "            data = r.json()\n",
    "            posts = data.get(\"posts\", [])\n",
    "            return [post.get(\"url\") for post in posts if \"url\" in post][:10]\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Source retrieval error for altmetric ID {altmetric_id}: {e}\")\n",
    "    return []\n",
    "\n",
    "def get_open_access_status(doi):\n",
    "    url = f\"https://api.unpaywall.org/v2/{doi}?email={UNPAYWALL_EMAIL}\"\n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "        if r.status_code == 200:\n",
    "            data = r.json()\n",
    "            return data.get(\"is_oa\", False), data.get(\"oa_status\", \"unknown\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Unpaywall error for DOI {doi}: {e}\")\n",
    "    return None, None\n",
    "\n",
    "def tag_keywords(text, keyword_list):\n",
    "    if not text:\n",
    "        return False\n",
    "    text = text.lower()\n",
    "    return any(k in text for k in keyword_list)\n",
    "\n",
    "# ---------- MAIN PROCESSING ----------\n",
    "def process_author(search_name):\n",
    "    logging.info(f\"🔍 Starting collection for: {search_name}\")\n",
    "    author_id, author_name = search_openalex_author_id(search_name)\n",
    "    if not author_id:\n",
    "        logging.warning(f\"No OpenAlex author found for: {search_name}\")\n",
    "        print(f\"❌ No author found for: {search_name}\")\n",
    "        return\n",
    "\n",
    "    works = get_openalex_author_works(author_id)\n",
    "    unique_works = {w['doi']: w for w in works if w.get(\"doi\")}.values()\n",
    "    logging.info(f\"Found {len(unique_works)} unique works with DOIs for {author_name}\")\n",
    "\n",
    "    results = []\n",
    "    for work in unique_works:\n",
    "        doi = work.get(\"doi\")\n",
    "        title = work.get(\"title\", \"Untitled\")\n",
    "        year = work.get(\"publication_year\", \"N/A\")\n",
    "        citations = work.get(\"cited_by_count\", 0)\n",
    "        authors = \"; \".join([auth['author']['display_name'] for auth in work.get(\"authorships\", [])])\n",
    "        venue = work.get(\"host_venue\", {}).get(\"display_name\", \"N/A\")\n",
    "        fields = \"; \".join([c[\"display_name\"] for c in work.get(\"concepts\", [])])\n",
    "        pub_type = \"Preprint\" if work.get(\"type\") == \"posted-content\" else \"Published\"\n",
    "\n",
    "        altmetric = get_altmetric_summary(doi)\n",
    "        altmetric_id = altmetric.get(\"altmetric_id\") if altmetric else None\n",
    "        sources = get_altmetric_sources(altmetric_id) if altmetric_id else []\n",
    "\n",
    "        oa_flag, oa_status = get_open_access_status(doi)\n",
    "\n",
    "        results.append({\n",
    "            \"Author\": author_name,\n",
    "            \"Paper Title\": title,\n",
    "            \"Year\": year,\n",
    "            \"Publication Type\": pub_type,\n",
    "            \"Citations\": citations,\n",
    "            \"DOI\": doi,\n",
    "            \"Authors\": authors,\n",
    "            \"Journal\": venue,\n",
    "            \"Fields\": fields,\n",
    "            \"Altmetric Score\": altmetric.get(\"score\", 0) if altmetric else 0,\n",
    "            \"Twitter Mentions\": altmetric.get(\"counts\", {}).get(\"Twitter\", 0) if altmetric else 0,\n",
    "            \"Reddit Mentions\": altmetric.get(\"counts\", {}).get(\"Reddit\", 0) if altmetric else 0,\n",
    "            \"News Mentions\": altmetric.get(\"counts\", {}).get(\"News\", 0) if altmetric else 0,\n",
    "            \"Policy Mentions\": altmetric.get(\"counts\", {}).get(\"Policy Docs\", 0) if altmetric else 0,\n",
    "            \"Mention URLs\": \"; \".join(sources),\n",
    "            \"Open Access\": oa_flag,\n",
    "            \"OA Status\": oa_status,\n",
    "            \"Public Health Impact\": tag_keywords(title, public_health_keywords),\n",
    "            \"Capacity Building\": tag_keywords(title, capacity_building_keywords)\n",
    "        })\n",
    "        time.sleep(1)\n",
    "\n",
    "    if results:\n",
    "        df = pd.DataFrame(results)\n",
    "        safe_name = author_name.lower().replace(' ', '_') if author_name else \"unknown_author\"\n",
    "\n",
    "        os.makedirs(\"csv\", exist_ok=True)\n",
    "        os.makedirs(\"json\", exist_ok=True)\n",
    "\n",
    "        csv_file = f\"csv/{safe_name}_impact_metrics.csv\"\n",
    "        json_file = f\"json/{safe_name}_impact_metrics.json\"\n",
    "\n",
    "        df.to_csv(csv_file, index=False)\n",
    "        df.to_json(json_file, orient=\"records\", indent=2)\n",
    "\n",
    "        logging.info(f\"✅ Saved for {search_name}: {csv_file}, {json_file}\")\n",
    "        print(f\"✅ Finished for {search_name} — {csv_file}\")\n",
    "    else:\n",
    "        logging.warning(f\"No valid papers found for {search_name}\")\n",
    "        print(f\"⚠️ No valid papers found for {search_name}\")\n",
    "\n",
    "# ---------- AUTHOR LOOP ----------\n",
    "author_list = [\n",
    "    \"Nicola Luigi Bragazzi\"\n",
    "]\n",
    "\n",
    "for name in author_list:\n",
    "    process_author(name)\n",
    "\n",
    "print(\"🎉 All authors processed. Check your output and log files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b6e2f2-aa3d-4824-8037-17f338959522",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
